{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "def load_emnist(file_path='emnist-bymerge.mat'):\n",
    "    \"\"\"\n",
    "    Loads training and test data with ntr and nts training and test samples\n",
    "    The `file_path` is the location of the `eminst-balanced.mat`.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Load the MATLAB file\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # Get the training data\n",
    "    Xtr = mat['dataset'][0][0][0][0][0][0][:]\n",
    "    ntr = Xtr.shape[0]\n",
    "    ytr = mat['dataset'][0][0][0][0][0][1][:].reshape(ntr).astype(int)\n",
    "    \n",
    "    # Get the test data\n",
    "    Xts = mat['dataset'][0][0][1][0][0][0][:]\n",
    "    nts = Xts.shape[0]\n",
    "    yts = mat['dataset'][0][0][1][0][0][1][:].reshape(nts).astype(int)\n",
    "    \n",
    "    print(\"%d training samples, %d test samples loaded\" % (ntr, nts))\n",
    "\n",
    "    return [Xtr, Xts, ytr, yts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697932 training samples, 116323 test samples loaded\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xts, ytr, yts = load_emnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(697932, 784) (116323, 784) (697932,) (116323,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape,Xts.shape,ytr.shape,yts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrd=np.reshape(Xtr,(697932,28,28),order='F')\n",
    "Xtsd=np.reshape(Xts,(116323,28,28),order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1847fc3ef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFnQiokCwoBMRBYIFnYgoECzoRESB+D+BVvnFr4exagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1847f1df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Xtrd[np.random.randint(1,20000),:,:],cmap='Greys_r')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Xtsd[np.random.randint(1,10000),:,:],cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntr = 35000\n",
    "nts = 10000\n",
    "\n",
    "# TODO: proper decide the number of samples and the ratio between dig and let\n",
    "\n",
    "# Create sub-sampled training and test data\n",
    "nsamp = Xtr.shape[0]\n",
    "Iperm = np.random.permutation(nsamp)\n",
    "Xtr1 = Xtrd[Iperm[:ntr],:,:]\n",
    "ytr1 = ytr[Iperm[:ntr]]\n",
    "nsamp = Xts.shape[0]\n",
    "Iperm = np.random.permutation(nsamp)\n",
    "Xts1 = Xtsd[Iperm[:nts],:,:]\n",
    "yts1 = yts[Iperm[:nts]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first we do it in 47 classes and add a dense layer to 36 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model #save and load models\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 28, 28, 1) (10000, 28, 28, 1) (35000, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = Xtr1.astype('float32')\n",
    "x_test = Xts1.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train=x_train.reshape((ntr,28,28,1))\n",
    "x_test=x_test.reshape((nts,28,28,1))\n",
    "y_train=ytr1.reshape((len(ytr1),1))\n",
    "y_test=yts1.reshape((len(yts1),1))\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r=np.where(y_train==36)\n",
    "y_train[r]=10\n",
    "t=np.where(y_test==36)\n",
    "y_test[t]=10\n",
    "\n",
    "r=np.where(y_train==37)\n",
    "y_train[r]=11\n",
    "t=np.where(y_test==37)\n",
    "y_test[t]=11\n",
    "\n",
    "r=np.where(y_train==38)\n",
    "y_train[r]=13\n",
    "t=np.where(y_test==38)\n",
    "y_test[t]=13\n",
    "\n",
    "r=np.where(y_train==39)\n",
    "y_train[r]=14\n",
    "t=np.where(y_test==39)\n",
    "y_test[t]=14\n",
    "\n",
    "r=np.where(y_train==40)\n",
    "y_train[r]=15\n",
    "t=np.where(y_test==40)\n",
    "y_test[t]=15\n",
    "\n",
    "r=np.where(y_train==41)\n",
    "y_train[r]=16\n",
    "t=np.where(y_test==41)\n",
    "y_test[t]=16\n",
    "\n",
    "r=np.where(y_train==42)\n",
    "y_train[r]=17\n",
    "t=np.where(y_test==42)\n",
    "y_test[t]=17\n",
    "\n",
    "r=np.where(y_train==43)\n",
    "y_train[r]=23\n",
    "t=np.where(y_test==43)\n",
    "y_test[t]=23\n",
    "\n",
    "r=np.where(y_train==44)\n",
    "y_train[r]=26\n",
    "t=np.where(y_test==44)\n",
    "y_test[t]=26\n",
    "\n",
    "r=np.where(y_train==45)\n",
    "y_train[r]=27\n",
    "t=np.where(y_test==45)\n",
    "y_test[t]=27\n",
    "\n",
    "r=np.where(y_train==46)\n",
    "y_train[r]=29\n",
    "t=np.where(y_test==46)\n",
    "y_test[t]=29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 8\n",
    "lrate = 0.05\n",
    "decay = lrate/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 36/62 channels?\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), \n",
    "                 padding='valid', \n",
    "                 input_shape=x_train.shape[1:],\n",
    "                 activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))   #+0.01\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(28, (3, 3), padding='valid', activation='relu'))   #+0.00\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dense(62, activation='relu'))   #+0.01\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(47, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(36, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               410112    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 47)                24111     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 47)                188       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36)                1728      \n",
      "=================================================================\n",
      "Total params: 451,083\n",
      "Trainable params: 448,301\n",
      "Non-trainable params: 2,782\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# initiate Adam optimizer\n",
    "opt = keras.optimizers.adam(lr=lrate, decay=decay)\n",
    "\n",
    "# Let's train the model using Adam\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "35000/35000 [==============================] - 52s 1ms/step - loss: 0.6977 - acc: 0.7706 - val_loss: 0.4569 - val_acc: 0.8496\n",
      "Epoch 2/8\n",
      "35000/35000 [==============================] - 52s 1ms/step - loss: 0.3757 - acc: 0.8621 - val_loss: 0.3938 - val_acc: 0.8617\n",
      "Epoch 3/8\n",
      "35000/35000 [==============================] - 48s 1ms/step - loss: 0.3037 - acc: 0.8843 - val_loss: 0.3504 - val_acc: 0.8775\n",
      "Epoch 4/8\n",
      "35000/35000 [==============================] - 47s 1ms/step - loss: 0.2695 - acc: 0.8966 - val_loss: 0.3471 - val_acc: 0.8806\n",
      "Epoch 5/8\n",
      "35000/35000 [==============================] - 48s 1ms/step - loss: 0.2368 - acc: 0.9068 - val_loss: 0.3508 - val_acc: 0.8787\n",
      "Epoch 6/8\n",
      "35000/35000 [==============================] - 49s 1ms/step - loss: 0.2137 - acc: 0.9151 - val_loss: 0.3557 - val_acc: 0.8801\n",
      "Epoch 7/8\n",
      "35000/35000 [==============================] - 52s 1ms/step - loss: 0.1946 - acc: 0.9219 - val_loss: 0.3670 - val_acc: 0.8792\n",
      "Epoch 8/8\n",
      "35000/35000 [==============================] - 51s 1ms/step - loss: 0.1833 - acc: 0.9253 - val_loss: 0.3582 - val_acc: 0.8858\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)\n",
    "hist_basic = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,\n",
    "                       validation_data=(x_test, y_test),shuffle=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then we go directly through 36 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               410112    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 443,524\n",
      "Trainable params: 440,836\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 35000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "35000/35000 [==============================] - 51s 1ms/step - loss: 0.9570 - acc: 0.7564 - val_loss: 0.4963 - val_acc: 0.8372\n",
      "Epoch 2/8\n",
      "35000/35000 [==============================] - 52s 1ms/step - loss: 0.3930 - acc: 0.8570 - val_loss: 0.3889 - val_acc: 0.8643\n",
      "Epoch 3/8\n",
      "35000/35000 [==============================] - 52s 1ms/step - loss: 0.3132 - acc: 0.8823 - val_loss: 0.3793 - val_acc: 0.8734\n",
      "Epoch 4/8\n",
      "35000/35000 [==============================] - 49s 1ms/step - loss: 0.2749 - acc: 0.8936 - val_loss: 0.3576 - val_acc: 0.8794\n",
      "Epoch 5/8\n",
      "35000/35000 [==============================] - 51s 1ms/step - loss: 0.2373 - acc: 0.9089 - val_loss: 0.3739 - val_acc: 0.8784\n",
      "Epoch 6/8\n",
      "35000/35000 [==============================] - 49s 1ms/step - loss: 0.2178 - acc: 0.9138 - val_loss: 0.3711 - val_acc: 0.8791\n",
      "Epoch 7/8\n",
      "35000/35000 [==============================] - 48s 1ms/step - loss: 0.1978 - acc: 0.9197 - val_loss: 0.3774 - val_acc: 0.8785\n",
      "Epoch 8/8\n",
      "35000/35000 [==============================] - 51s 1ms/step - loss: 0.1840 - acc: 0.9237 - val_loss: 0.3864 - val_acc: 0.8826\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: 36/62 channels?\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), \n",
    "                 padding='valid', \n",
    "                 input_shape=x_train.shape[1:],\n",
    "                 activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))   #+0.01\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(28, (3, 3), padding='valid', activation='relu'))   #+0.00\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dense(62, activation='relu'))   #+0.01\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "# initiate Adam optimizer\n",
    "opt = keras.optimizers.adam(lr=lrate, decay=decay)\n",
    "\n",
    "# Let's train the model using Adam\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "seed=7\n",
    "np.random.seed(seed)\n",
    "hist_basic = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,\n",
    "                       validation_data=(x_test, y_test),shuffle=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 47 to 36: 0.8858, trainable paras:448,301\n",
    "# 36: 0.8826, trainable paras:440,836"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
